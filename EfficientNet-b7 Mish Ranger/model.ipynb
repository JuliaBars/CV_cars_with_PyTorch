{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "# @lukemelas EfficientNet implementation: https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Modified version of @lukemelas' EfficientNet implementation with Mish instead of Swish activation\n",
    "from MEfficientNet_PyTorch.efficientnet_pytorch import EfficientNet as MEfficientNet\n",
    "\n",
    "# @lessw2020 implementation : https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer/blob/master/ranger.py\n",
    "# version 9.3.19 used\n",
    "from ranger import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "labels_df = pd.read_csv('labels_df.csv')\n",
    "labels_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(SZ:int=299):\n",
    "    SEED = 42\n",
    "    LABEL = 'class_name'\n",
    "    \n",
    "    # Full training set for training, full test set for validation\n",
    "    src_test = (ImageList.from_df(labels_df, path, folder='merged', cols='filename')\n",
    "           # the 'is_test' column has values of 1 for the test set\n",
    "           .split_from_df(col='is_test')\n",
    "           .label_from_df(cols=LABEL))\n",
    "\n",
    "    data_test = (src_test.transform(car_tfms, \n",
    "                                  size=SZ,  \n",
    "                                  resize_method=ResizeMethod.SQUISH, \n",
    "                                  padding_mode='reflection')\n",
    "                .databunch()\n",
    "                .normalize(imagenet_stats))\n",
    "    \n",
    "    return data_test\n",
    "\n",
    "data_test = get_data(SZ=456, do_cutout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "\n",
    "def FlatCosAnnealScheduler(learn, lr:float=4e-3, tot_epochs:int=1, moms:Floats=(0.95,0.999),\n",
    "                          start_pct:float=0.72, curve='cosine'):\n",
    "    \"Manage FCFit trainnig as found in the ImageNette experiments\"\n",
    "    n = len(learn.data.train_dl)\n",
    "    anneal_start = int(n * tot_epochs * start_pct)\n",
    "    batch_finish = ((n * tot_epochs) - anneal_start)\n",
    "    if curve==\"cosine\":\n",
    "        curve_type=annealing_cos\n",
    "    elif curve==\"linear\":\n",
    "        curve_type=annealing_linear\n",
    "    elif curve==\"exponential\":\n",
    "        curve_type=annealing_exp\n",
    "    else:\n",
    "        raiseValueError(f\"annealing type not supported {curve}\")\n",
    "\n",
    "    phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr).schedule_hp('mom', moms[0])\n",
    "    phase1 = TrainingPhase(batch_finish).schedule_hp('lr', lr, anneal=curve_type).schedule_hp('mom', moms[1])\n",
    "    phases = [phase0, phase1]\n",
    "    return GeneralScheduler(learn, phases)\n",
    "                \n",
    "def fit_fc(learn:Learner, tot_epochs:int=None, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
    "                  wd:float=None, callbacks:Optional[CallbackList]=None, show_curve:bool=False)->None:\n",
    "    \"Fit a model with Flat Cosine Annealing\"\n",
    "    max_lr = learn.lr_range(lr)\n",
    "    callbacks = listify(callbacks)\n",
    "    callbacks.append(FlatCosAnnealScheduler(learn, lr, moms=moms, start_pct=start_pct, tot_epochs=tot_epochs))\n",
    "    learn.fit(tot_epochs, max_lr, wd=wd, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet_b7 = 'efficientnet-b7'\n",
    "def getMishModel(data, model_name):\n",
    "    model = MEfficientNet.from_pretrained(model_name, data.c)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mish_model = getMishModel(data_test, effnet_b7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from ranger import Ranger\n",
    "\n",
    "data_test.batch_size = 12\n",
    "\n",
    "learn = Learner(data_test, \n",
    "                model=mish_model,\n",
    "                wd = 1e-3,\n",
    "                opt_func=Ranger,\n",
    "                bn_wd=False,\n",
    "                true_wd=True,\n",
    "                metrics=[accuracy],\n",
    "                loss_func=LabelSmoothingCrossEntropy(),\n",
    "                # callback_fns=BnFreeze\n",
    "               ).to_fp16()\n",
    "\n",
    "fit_fc(learn, tot_epochs=40, lr=15e-4, start_pct=0.1, wd=1e-3, show_curve=False)\n",
    "\n",
    "# SZ 456 - 5 - lr: 15e-4, start_pct=0.10, wd1e-3"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
